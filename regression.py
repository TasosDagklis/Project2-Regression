# -*- coding: utf-8 -*-
"""Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivsQlv1AewiJxzLyklhAWikB6kihuAlR

Παλινδρόμηση με νευρωνικά δίκτυα και το climate change dataset.

## Φόρτωση και προεργασία

Φόρτωση βιβλιοθηκών, φόρτωση και απεικόνιση δεδομένων
"""

# Εισάγουμε όλες τις απαραίτητες βιβλιοθήκες
import pandas as pd
import numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split

# Φορτώνουμε το αρχείο CSV με τη βιβλιοθήκη Pandas μόνο για λόγους απεικόνισης
dataframe = pd.read_csv('climate_change.csv')
print(dataframe.head(5))
print("Διαστάσεις:", dataframe.shape)

"""## Δημιουργία custom αντικειμένου Dataset

Δημιουργούμε ένα αντικείμενο Dataset το οποίο θα τροφοδοτήσει τους dataloaders, και ένα αντικείμενο transform που θα τροποποιεί τα δεδομένα πριν διαβαστούν από τους loaders.

"""

class ClimateDataset(torch.utils.data.Dataset):
  def __init__(self, csv_file, transform=None, train=True):
    """
    Args:
      csv_file (string): Path to the csv file
      transform (callable, optional): Optional transform to be applied
          on each sample.
      train (bool): whether to create the training set or the test set
    """

    # Ορίζουμε το μέγεθος του training set
    train_set_size = 250

    # Φόρτωση του csv μέσω Pandas, διαγραφή στηλών που δε βοηθούν στην ανάλυση,
    # μετατροπή των Pandas Dataframes σε Numpy Arrays, που έχουν πιο βοηθητικές
    # ιδιότητες
    dataframe = pd.read_csv(csv_file)
    targets = np.array(dataframe[['Temp']]).astype('float32')
    data = np.array(dataframe.drop(columns=['Year','Month','Temp'])).astype('float32')

    # Διαχωρισμός των δεδομένων σε training και test set
    # Αυτή η γραμμή θα πρέπει στο μέλλον να αντικατασταθεί αν θέλουμε να κάνουμε 
    # πιο ρεαλιστική αξιολόγηση
    # Θέτουμε και το seed στο random state για λόγους επαναληψιμότητας
    train_data, test_data, train_targets, test_targets = train_test_split(data, 
                            targets, train_size=train_set_size, random_state=665)
    
    # Θέτουμε και αρχικοποιούμε το transform
    self.transform = transform
    self.transform.fit(train_data, train_targets)
 
    if train==True:
      self.data = train_data
      self.targets = train_targets
    else:
      self.data = test_data
      self.targets = test_targets

  def __len__(self):
    return len(self.targets)

  def __getitem__(self, idx):
    if torch.is_tensor(idx):
      idx = idx.tolist()
    item_data = self.data[idx,:]
    item_target = self.targets[idx,:]
    
    if self.transform:
      item_data, item_target = self.transform(item_data, item_target)
    return item_data, item_target


# Η κλάση αυτή θα παίξει το ρόλο του Transform. Θα αφαιρεί την ελάχιστη τιμή
# από κάθε στήλη των δεδομένων και θα διαιρεί με το φάσμα της, ώστε να κανονικοποιεί
# τις τιμές όλων των μεταβλητών (και των στόχων) στο [0,1]
class MinMaxScaler():

  def fit(self, data, targets):
    self.data_min = data.min(0, keepdims=True)
    self.target_min = targets.min(0, keepdims=True)
    self.data_max = data.max(0, keepdims=True)
    self.target_max = targets.max(0, keepdims=True)
    return self

  def __call__(self, data, target):
    data = (data - self.data_min)/(self.data_max-self.data_min)
    target = (target - self.target_min)/(self.target_max-self.target_min)
    return data, target

  def inverse_transform(self, data, target):
    data=data * (self.data_max-self.data_min) + self.data_min
    target = target * (self.target_max-self.target_min) + self.target_min
    return data, target

"""## Δημιουργία DataLoaders

Δημιουργούμε dataloaders για το training set και για το test set.
"""

batch_size = 500
transform = MinMaxScaler()

train_dataset = ClimateDataset(csv_file='climate_change.csv', train=True, transform=transform)
test_dataset = ClimateDataset(csv_file='climate_change.csv', train=False, transform=transform)

train_dataloader = DataLoader(train_dataset, batch_size=batch_size)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size)

"""# **Μεμονωμένος νευρώνας**

## Αρχιτεκτονική δικτύου

Ορίζουμε ένα απλό δίκτυο με έναν νευρώνα για γραμμική παλινδρόμηση
"""

# Κώδικας ορισμού του δικτύου
class NeuralNetwork1(nn.Module):
  def __init__(self):
      super(NeuralNetwork1, self).__init__()
      self.flatten = nn.Flatten()
      self.network_architecture = nn.Sequential(
            nn.Linear(8, 1)
        )

  def forward(self, x):
      x = self.flatten(x)
      logits = self.network_architecture(x)
      return logits

"""## Training και Test Loop

Γράφουμε τον κώδικα του training loop και του test loop
"""

def train_loop(dataloader, model, loss_fn, optimizer, epoch):
    size = len(dataloader.dataset)
    for batch, (X, y) in enumerate(dataloader):
        # Compute prediction and loss
        pred = model(X)
        y = np.reshape(y, (250,1))
        loss = loss_fn(pred, y)
        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        #print the loss per 100 epochs
        if epoch % 100 == 0:
            loss, current = loss.item(), epoch * len(X)
            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")

def test_loop(dataloader, model, loss_fn):
    test_loss = 0
    num_batches = len(dataloader)
    with torch.no_grad():
        for X, y in dataloader:
            pred = model(X)
            y = np.reshape(y, (58,1))
            test_loss += loss_fn(pred, y).item()

    test_loss /= num_batches
    print(f"Test Error: \n R2 score: {(100*r2_score(y, pred)):>0.1f}%, Avg loss: {test_loss:>8f} \n")

"""## Ορισμός υπερπαραμέτρων και εκπαίδευση δικτύου

Κώδικας εκτέλεσης και αξιολόγησης του δικτύου 
"""

torch.manual_seed(100)
model = NeuralNetwork1()
learning_rate = 0.001
epochs = 3000
loss_fn = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# Κώδικας εκπαίδευσης εδώ:
for t in range(epochs+1):
    print(f"Epoch {t+1}\n-------------------------------")
    train_loop(train_dataloader, model, loss_fn, optimizer, t)
    #call the test loop per 100 epochs
    if t % 100 == 0:
      test_loop(test_dataloader, model, loss_fn)
print("Done!")

"""# **Νευρωνικό Δίκτυο**

# Αρχιτεκτονική Νευρωνικού Δικτύου
Ορίζουμε ένα δίκτυο που αποτελείται από δύο κρυφά στρώματα με 100 νευρώνες το καθένα.
"""

class NeuralNetwork2(nn.Module):
  def __init__(self):
      super(NeuralNetwork2, self).__init__()
      self.flatten = nn.Flatten()
      self.network_architecture = nn.Sequential(
           nn.Linear(8, 100),
           nn.ReLU(),
           nn.Linear(100, 100),
           nn.ReLU(),
           nn.Linear(100, 1),
        )

  def forward(self, x):
      x = self.flatten(x)
      logits = self.network_architecture(x)
      return logits

"""# Training και Test Loop
Κώδικας του training loop και του test loop
"""

def train_loop(dataloader, model, loss_fn, optimizer, epoch):
    size =  len(dataloader.dataset)
    for batch, (X, y) in enumerate(dataloader):
      # Compute prediction and loss
        pred = model(X)
        y = np.reshape(y, (250,1))
        loss = loss_fn(pred, y)
        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        #print the loss per 100 epochs
        if epoch % 100 == 0:
            loss, current = loss.item(), epoch * len(X)
            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")

def test_loop(dataloader, model, loss_fn):
    num_batches = len(dataloader)
    test_loss = 0
    with torch.no_grad():
        for X, y in dataloader:
            pred = model(X)
            y = np.reshape(y, (58,1))
            test_loss += loss_fn(pred, y).item()

    test_loss /= num_batches
    print(f"Test Error: \n R2 score: {(100*r2_score(y, pred)):>0.1f}%, Avg loss: {test_loss:>8f} \n")

"""# Ορισμός υπερπαραμέτρων και εκπαίδευση δικτύου
Κώδικας εκτέλεσης και αξιολόγησης δικτύου
"""

torch.manual_seed(50)
model = NeuralNetwork2()
learning_rate = 0.001
epochs = 3000
loss_fn = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

# Κώδικας εκπαίδευσης εδώ:
for t in range(epochs+1):
    print(f"Epoch {t+1}\n-------------------------------")
    train_loop(train_dataloader, model, loss_fn, optimizer, t)
    if t % 100 == 0:
      test_loop(test_dataloader, model, loss_fn)
print("Done!")